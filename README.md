# ðŸ“¡ S3 to RDS Data Ingestion Pipeline

This project implements a fully automated, event-driven ETL pipeline that ingests CSV data files from Amazon S3 and writes them into an Amazon RDS PostgreSQL database. The solution leverages AWS Lambda, Python, and the Serverless Framework for scalable and maintainable infrastructure management.

---

## ðŸŽ¯ Objective

- Automatically trigger a Lambda function on new file uploads to a specific S3 bucket.
- Download, parse, and validate CSV files.
- Insert or upsert data into an RDS PostgreSQL table.
- Log events and errors via CloudWatch.
- Manage infrastructure using the Serverless Framework.

---

## âœ… Features & Acceptance Criteria

- âœ… **Trigger:** Lambda is invoked upon new uploads to an S3 bucket/prefix.
- âœ… **ETL Logic:**
  - Downloads file using `boto3`
  - Parses and validates CSV content
  - Connects to PostgreSQL with `psycopg2`
  - Inserts or upserts rows using transactions
- âœ… **Error Handling:**
  - Handles schema mismatches and DB failures gracefully
  - Logs all events and errors to CloudWatch
- âœ… **Deployment:**
  - Fully deployed and configured using the Serverless Framework
- âœ… **Code Quality:**
  - Modular, clean, and documented